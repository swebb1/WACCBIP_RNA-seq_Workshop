[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WACCBIP RNA-seq workshop",
    "section": "",
    "text": "This is the homepage for the RNA-seq analysis course for biologists at the University of Edinburgh.\n\n\n\nThis workshop is designed as an introduction to RNA-seq data analysis and will guide you through the following steps:\n\nRNA-seq analysis on the command line\n\nAssessing raw sequence data and performing quality control\nAligning sequence reads to a reference genome\nFiltering alignments for further analysis\nAssessing the quality of your RNA-seq experiment\nVisualising alignments on a genome browser\nQuantifying expression levels\n\n\n\nDifferential expression analysis with DESeq2\n\nLoad transcript abundance files into R\nRun DESeq2 and visualise results\nExtract differentially expressed genes\nVisualise differentially expressed genes\n\nThere is no such thing as a default pipeline. Although we mostly use standard parameters in this tutorial we hope to make you aware of the considerations you should take at each step. Make sure you understand your data and where it has come from. Use the correct tools for your dataset and read the tool documentation to see how different parameters affect your output!\nThis workshop is partly modeled on the training materials already provided by the Harvard Chan Bioinformatics Core. Please check out their website for comprehensive training materials in RNA-seq, NGS analysis and bioinformatics.\n\nFor more information contact Shaun Webb."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "lesson2_DESeq2.html",
    "href": "lesson2_DESeq2.html",
    "title": "Differential Expression with DESeq2",
    "section": "",
    "text": "Install the DESeq2 package for use in R and RStudio\nCreate a sample sheet for your differential expression analysis\nImport transcript abundance data from Salmon into a DESeq2 object\nRun differential expression analysis with DESeq2\nAssess replicate and sample groups (PCA plots and hierarchical clustering)\nExtract and visualise results (MA plots, scatter plots, volcano plots)"
  },
  {
    "objectID": "lesson2_DESeq2.html#getting-started",
    "href": "lesson2_DESeq2.html#getting-started",
    "title": "Differential Expression with DESeq2",
    "section": "1. Getting Started",
    "text": "1. Getting Started\nDifferential expression (DE) analysis is commonly performed downstream of RNA-seq data analysis and quantification. We use statistical methods to test for differences in expression of individual genes between two or more sample groups. In this lesson, we will use the statistical programming language R and the DESeq2 package, specifically designed for differential expression analysis.\n\nR and RStudio\nR is an extremely powerful programming language for working with large datasets, applying statistical tests and creating publication ready graphics. RStudio is an Integrated Development Environment (IDE) for R which provides a graphical and interactive environment for R programming.\nWe recommend that you understand the basics of R and RStudio and follow at least the getting started and R and RStudio sections of the Introduction to R workshop. You can choose to run RStudio on your own laptop or log into the aabn RStudio server.\n\n\nInstalling DESeq2\nDESeq2 is part of the Bioconductor repository of biology specific R packages. You can install DESeq2 using the Bioconductor manager with the code below in the R Console. These should already be installed in RStudio on the aabn server so you will not need to run this.\n\n### YOU DO NOT NEED TO RUN THIS CODE!!\n\n## Install Bioconductor packages\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"DESeq2\")\nBiocManager::install(\"GenomicFeatures\")\nBiocManager::install(\"tximport\")\nBiocManager::install(\"apeglm\")\n\n## Install CRAN packages\ninstall.packages(\"tidyverse\")\ninstall.packages(\"RColorBrewer\")\ninstall.packages(\"pheatmap\")\n\n\n\nCreate a project\nUse the project drop-down menu at the top right to create a new project called Differential expression workshop or something similar and choose an appropriate working directory.\n\n\nInput data\nDESeq2 works with matrices of read counts per gene for multiple samples. In the past we used read counting software like HTSeq-count or featureCounts to quantify counts of aligned reads (e.g. from STAR) over exons for each gene model. The standard practice now is to use pseudocounts from tools like Salmon which do a much better job at estimating expression levels by:\n\nCorrecting for sequencing biases e.g. GC content\nCorrecting differences in individual transcript lengths\nIncluding reads that map to multiple genes\nProducing much smaller output files than aligners\n\nDESeq2 requires non-normalised or “raw” count estimates at the gene-level for performing DE analysis. We will use the R package tximport to import read counts and summarise transcript abundance estimates for each gene.\nIn the previous lessons we generated tables of transcript abundances (quant.sf) for each sample with Salmon, using a reduced set of RNA-seq sequencing reads. As input to DESeq2 we will use similar tables generated from the full dataset.\nTo access these files:\n\nOpen the Terminal window in RStudio\n\nThis is a bash terminal on the server\n\nLink the data folder to your project folder using the Linux ln command\n\nln -s /data/swebb/training/RNA-seq_analysis/lesson_2/salmon .\n\n\n\n\nExperimental design\nWe will also include a further two samples from the original publication which correspond to a MOV10 knock-down cell line using siRNA. We will use this data to investigate changes in transcription upon perturbation of MOV10 expression relative to the control (irrelevant siRNA) experiment.\n\n\n\nDataset\nDescription\n\n\n\n\nControl_1\nControl, replicate 1\n\n\nControl_2\nControl, replicate 2\n\n\nControl_3\nControl, replicate 3\n\n\nMOV10_OE_1\nMOV10 over-expression, replicate 1\n\n\nMOV10_OE_2\nMOV10 over-expression, replicate 2\n\n\nMOV10_OE_3\nMOV10 over-expression, replicate 3\n\n\nMOV10_KD_2\nMOV10 knock-down, replicate 2\n\n\nMOV10_KD_3\nMOV10 knock-down, replicate 3\n\n\n\nMOV10 is an RNA helicase reported to associate with FMR1, a protein found in the brain and linked to fragile X syndrome.\n\n\nNotes on experimental design\nDESeq2 and other differential expression tools perform statistical analysis by comparing mean expression levels between sample groups. Accurate mean estimates can only be achieved with precise estimates of the biological variation between independent samples.\nIn DE experiments, increasing the number of biological replicates is generally more desirable than increasing read depth in single samples, unless you are particularly interested in rare RNAs. DESeq2 will not work if a sample group only has one replicate and it is recommended to have at least 3.\nIf you have technical replicates in your experimental design, these should be merged into one sample to represent a single biological replicate.\nWe also need to ensure (as much as possible) that any effect we see between groups can be attributed to differences in biology rather than confounding factors in the design or batch effects introduced at the library preparation stage.\n\n\n Further Learning\n\nRead this document on experimental design considerations in differential expression analysis.\n\n\n\nThe DESeq2 method\nDESeq2 performs statistical analysis of un-normalised raw/estimated read count data per gene. It uses a median of ratios normalisation method to account for differences in sequencing depth and RNA composition between samples.\nCount data is modeled using a generalised linear model based on the negative binomial distribution, with a fitted mean and a gene-specific dispersion parameter which describes the relationship between variance in the count data and the observed mean.\nThe model coefficient represents the change in mean between sample groups giving us log2 fold change values per gene. By default, DESeq2 performs the Wald test to test for significant changes in gene expression between sample groups and generate p-values which are then adjusted for multiple testing.\nDESeq2 has internal methods for:\n\nEstimating size factors (sample normalisation)\nEstimating dispersions\nFitting the negative binomial GLM (log2 fold changes)\nFiltering outliers and low count genes\nStatistical tests between sample groups (p-values)\nMultiple testing correction (FDR adjusted p-value)\n\n\n\n\nComprehensive tutorials\nThis is a lightweight introduction to differential expression analysis. For a comprehensive overview of the DESeq2 method, functionality and complex experimental designs, check out the following resources:\n\nDESeq2 tutorial\nRNAseq analysis with DESeq2\nHBC Differential expression workshop\n\n\n\n Key points:\n\n\nSetup R and RStudio and install required packages\nDownload the required datasets\nUnderstand considerations for experimental design\nUnderstand an overview of the DESeq2 methodology"
  },
  {
    "objectID": "lesson2_DESeq2.html#create-a-sample-file",
    "href": "lesson2_DESeq2.html#create-a-sample-file",
    "title": "Differential Expression with DESeq2",
    "section": "2. Create a sample file",
    "text": "2. Create a sample file\nThe first step in our analysis is to create a tab separated file of sample IDs and metadata. This already exists in the folder you downloaded earlier but you would normally create this manually. We can then import the sample sheet to R with the read_tsv() function from readr.\n\nlibrary(tidyverse)\nss<-read_tsv(\"salmon/samples.tsv\",col_names = T,col_types = \"fff\")\nss\n\n# A tibble: 8 × 3\n  sample     condition replicate\n  <fct>      <fct>     <fct>    \n1 Control_1  Control   1        \n2 Control_2  Control   2        \n3 Control_3  Control   3        \n4 MOV10_KD_2 MOV10_KD  2        \n5 MOV10_KD_3 MOV10_KD  3        \n6 MOV10_OE_1 MOV10_OE  1        \n7 MOV10_OE_2 MOV10_OE  2        \n8 MOV10_OE_3 MOV10_OE  3        \n\n\n\n\n Key points:\n\n\nThe sample file should contain metadata on each sample\nIt is important to include all known variables that could confound results or explain technical variance"
  },
  {
    "objectID": "lesson2_DESeq2.html#importing-count-data-with-tximport",
    "href": "lesson2_DESeq2.html#importing-count-data-with-tximport",
    "title": "Differential Expression with DESeq2",
    "section": "3. Importing count data with tximport",
    "text": "3. Importing count data with tximport\nWe will start by importing the count data for each sample into R. We will use the package tximportto read the Salmon transcript count files and create a matrix of read counts for each gene. The tximeta package is also worth looking at as it can auto-detect the genome you have used and download the metadata.\n\nlibrary(DESeq2)\nlibrary(tximport)\nlibrary(GenomicFeatures)\n\n## List all of our salmon quant.sf files\nfiles <- file.path(\"salmon\",ss$sample,\"quant.sf\")\nnames(files) <- ss$sample\n\n## Get the tx2gene map file\ntx2gene <- read_tsv(\"salmon/salmon_tx2gene.tsv\")\n\n## Import the transcript counts and summarise to gene counts\ntxi <- tximport(files, type = \"salmon\", tx2gene = tx2gene)\n\nWe must supply a map between transcript IDs and gene IDs for our annotations, so that the function can summarise counts at gene level. In the example above we read in salmon_tx2gene.tsv. This map can also be generated from a gtf annotation file using the code below:\n\n### YOU DO NOT NEED TO RUN THIS CODE!!\n\n## Make a Transcript DB object from our gene annotation GTF file\ntxdb<-makeTxDbFromGFF(organism = \"Homo sapiens\",file = \"/data/swebb/training/RNA-seq_analysis/annotation/Homo_sapiens.GRCh38.106.gtf\",format = \"gtf\")\ntxdb<-makeTxDbFromGFF(organism = \"Homo sapiens\",file = \"RNA-seq_anannotation/Homo_sapiens.GRCh38.106.gtf\",format = \"gtf\")\n## Extract mappings from transcriptID to geneID\nk <- keys(txdb, keytype = \"TXNAME\")\ntx2gene <- select(txdb, k, \"GENEID\", \"TXNAME\")\n\nNow that we have per-gene count data, we can import this into DESeq2. We need to supply the txi object we have just created as well as a design.\nThe simplest design is just to compare our samples by the condition column (Control, MOV10_KD, MOV10_OE). The design is a formula in R so is preceded with the ~ character.\n\n\n Further Learning\n\nHave a look at these resources for advice on complex experimental designs (e.g. multiple variables of interest, interaction terms, time-course analysis:\n\nDESeq2 manual\nTime-course analysis example\nLikelihood ratio test for measuring changes across multiple sample groups at once.\n\n\n\n\n\n Key points:\n\n\nImport pseudo-count data into R with tximeta or tximport\nDESeq2 expects gene-level counts\nSummarise transcript counts to gene counts"
  },
  {
    "objectID": "lesson2_DESeq2.html#creating-a-deseq-object-and-running-deseq",
    "href": "lesson2_DESeq2.html#creating-a-deseq-object-and-running-deseq",
    "title": "Differential Expression with DESeq2",
    "section": "4. Creating a DESeq object and running DESeq",
    "text": "4. Creating a DESeq object and running DESeq\n\n## Create the DESeq dataset object\ndds <- DESeqDataSetFromTximport(txi, ss, ~ condition)\n\nusing counts and average transcript lengths from tximport\n\ndds\n\nclass: DESeqDataSet \ndim: 58396 8 \nmetadata(1): version\nassays(2): counts avgTxLength\nrownames(58396): ENSG00000000003 ENSG00000000005 ... ENSG00000289718\n  ENSG00000289719\nrowData names(0):\ncolnames(8): Control_1 Control_2 ... MOV10_OE_2 MOV10_OE_3\ncolData names(3): sample condition replicate\n\n\nThe condition column is represented in R as a factor, or categorical variable, which has levels.\n\nlevels(dds$condition)\n\n[1] \"Control\"  \"MOV10_KD\" \"MOV10_OE\"\n\n\nBy default, the levels are set in alphabetical order and DESeq2 will always assume that the first level is your control group to which it will compare datasets. In this case we are okay, otherwise you will need to relevel your condition column or explicitly reference the condition comparisons of interest in your results (see below).\nLet’s create a list of comparisons, known as contrasts, that we want to look at. Here we will put our base-level or control sample last. We will also set a few other variables to help name our outputs.\n\ncontrasts<-list(c(\"condition\",\"MOV10_OE\",\"Control\"),\n           c(\"condition\",\"MOV10_KD\",\"Control\"))\n\n## As well as contrasts, DESeq also uses coefficients to name results. We can create these from our specified contrasts\ncoefficients<-contrasts %>% map(~paste(.x[1],.x[2],\"vs\",.x[3],sep = \"_\")) %>% unlist()\n\n## Simple project ID\nproject=\"MOV10\"\n\n## Labels for QC plots - we can add all possible confounding factors from our colData\nlabels= c(\"condition\",\"replicate\")\n## Merge colData into label names in a data frame\ncnames <- colData(dds) %>% \n  as_tibble() %>% \n  unite(all_of(labels), col = label, sep = \"-\") %>% \n  pull(label)\n\n## Thresholds for p-value and fold change to filter and summarise results later\npadj_thresh = 0.05\nl2fc_thresh = 0 ## Just include all significant genes here\n\nNow we are ready to run DESeq. The DESeq function has internal methods to:\n\nEstimate size factors to normalise gene counts per sample\nEstimate gene-wise dispersions to measure variance in the dataset\nShrink gene-wise dispersions to improve the dispersion estimates\nFit a negative binomial statistical model to the data\nPerform statistical testing with the Wald Test or Likelihood Ratio Test\n\n\n## run DESeq\ndds <- DESeq(dds)\n\nestimating size factors\n\n\nusing 'avgTxLength' from assays(dds), correcting for library size\n\n\nestimating dispersions\n\n\ngene-wise dispersion estimates\n\n\nmean-dispersion relationship\n\n\nfinal dispersion estimates\n\n\nfitting model and testing\n\n## save dds object as a file - saveRDS can save R objects\nsaveRDS(dds,file =paste0(project,\".dds.RDS\"))\n\n\nPlot dispersions\nIt can be useful to plot the gene-level dispersion estimates to ensure the DESeq model is right for your data. You should find that dispersion is generally lower for genes with higher read counts, that final dispersion levels have been shrunk towards the fitted model and that a few outliers exist which have not been shrunk. If the red line is not a good generalisation for your data then DE analysis with DESeq2 may not be appropriate.\n\n#Plot dispersions\nplotDispEsts(dds, main=\"Dispersion plot\")\n\n\n\n\n\n\n Key points:\n\n\nCreate a DESeq dataset from count data\nUnderstand the DESeq design parameter\nRun the DESeq function and understand the internal steps\nPlot dispersions to assess the fitted model"
  },
  {
    "objectID": "lesson2_DESeq2.html#deseq-quality-control",
    "href": "lesson2_DESeq2.html#deseq-quality-control",
    "title": "Differential Expression with DESeq2",
    "section": "5. DESeq quality control",
    "text": "5. DESeq quality control\nBefore we look at the results of differential expression tests we first want to perform some quality control by visualising and assessing the entire dataset. The raw counts are not optimal for visualisation and clustering so we will apply a regularised log transformation which reduces the bias from genes with extremely low and high counts. The rld() function can take a while to run with large datasets.\n\n## Log transformed data\nrld <- rlog(dds, blind=F)\nsaveRDS(rld,file =paste0(project,\".rld.RDS\"))\n\n\n\n\n Further Learning\n\nYou can read more on DESeq2 data transformations here.\n\n\nHeatmap of Sample Distances\nWe can use our log transformed data to perform sample clustering. Here, we calculate sample distances by applying the dist() function to our transformed read count matrix.\nBy default, the dist() function calculates euclidean distances between the rows of a matirx. We have to transpose our read count table first to calculate distances between samples (columns). The distance calculated is a measure of the distance between two vectors, in this case the read counts for all genes:\n# euclidean(a,b) = sqrt(sum((a - b)^2))\nA heatmap of this distance matrix gives us an overview of similarities and dissimilarities between samples.\n\nlibrary(\"pheatmap\") #  heatmap plotting package\nlibrary(\"RColorBrewer\") # colour scales\n\nsampleDists <- dist(t(assay(rld))) ## t() function transposes a matrix\nsampleDistMatrix <- as.matrix(sampleDists)\nrownames(sampleDistMatrix) <- as.list(cnames)\ncolnames(sampleDistMatrix) <- as.list(cnames)\ncols <- colorRampPalette( rev(brewer.pal(9, \"Blues\")) )(255) ## Set a colour pallette in shades of blue\npheatmap(sampleDistMatrix,\n         clustering_distance_rows=sampleDists,\n         clustering_distance_cols=sampleDists,\n         col=cols)\n\n\n\n\n\n\nPrinciple Component Analysis\nAnother way to visualize sample-to-sample distances is a principal components analysis (PCA). In this method, the data points (here, the samples) are projected onto a 2D plane such that they spread out in the two directions that explain most of the variation in the data.\nThe x-axis is the direction that separates the data points the most. The values of the samples in this direction are written PC1 (principle component 1). The y-axis is a direction that separates the data the second most, PC2. The percent of the total variance that is contained in each direction is printed on the axis label. Note that these percentages do not add to 100%, because there are more dimensions that contain the remaining variance.\nWe expect to see our samples divide by their biological condition or some other source of variation that we are aware of (e.g. sex, cell type, batches of library preparation etc). If you do not see your samples separating by your variable of interest you may want to plot out PC3 and PC4 to see if it appears there. If there is a large amount of variance introduced by other factors or batch effects then you will need to control for these in your experimental design. See the DESeq2 vignette for more details.\nWe will run the PCA analysis with the DESeq2 command plotPCA().\n\n## Principle component analysis - get the PCA data\nplotPCA(rld, intgroup=c(labels[1],labels[length(labels)]))\n\n\n\n\nIf we don’t like the default plotting style we can ask plotPCA to return the data only and create our own custom plot. Below, we use ggplot, a sophisticated plotting package in R.\n\n## Principle component analysis - get the PCA data\npca<-plotPCA(rld, intgroup=c(labels[1],labels[length(labels)]),returnData=T)\n\n## Plot with ggplot\nggplot(pca,aes(PC1,PC2,colour=condition,shape=replicate)) + \n  geom_point(size=3) +\n  theme_bw() + \n  theme(legend.key = element_blank()) + \n  xlab(paste(\"PC1:\",round(attr(pca,\"percentVar\")[1]*100),\"%\")) + \n  ylab(paste(\"PC1:\",round(attr(pca,\"percentVar\")[2]*100),\"%\"))\n\n\n\n\n\n\nHeatmap of genes with the largest variance\nIt may also be useful to take an initial look at the genes with the highest amount of variation across the dataset. We should expect to see some genes which appear to be differentially expressed between sample groups.\n\n## Get the top 20 genes after ordering the rld counts by variance\ntopVarGenes <- head(order(-rowVars(assay(rld),useNames = T)),20)\n\n## Create a matrix from these genes only\nmat <- assay(rld)[topVarGenes, ] \nanno<-as.data.frame(colData(dds)[,labels])\npheatmap(mat,cluster_rows = F,cluster_cols = F,show_rownames = T,scale=\"row\",annotation_col = anno)\n\n\n\n\n\n\n Discussion\n\nCan you guess which gene has the Ensembl identifier ENSG00000155363?\n\n\n\nPlot Individual Gene Counts\nIn certain cases like ours, where we know the expression levels of particular genes should change between sample groups, we may want to plot individual gene counts. Let’s plot normalised gene counts for the MOV10 gene (ENSG00000155363).\n\n## Get normalised counts for a single gene\ngene=\"ENSG00000155363\"\ngeneData <- plotCounts(dds, gene=gene, intgroup=labels, returnData=TRUE,normalized = T)\n\n## Plot with ggplot\nggplot(geneData, aes_string(x=labels[1], y=\"count\",fill=labels[length(labels)])) + \n  scale_y_log10() + \n  geom_dotplot(binaxis=\"y\", stackdir=\"center\") + \n  theme_bw() + \n  theme(legend.key = element_blank()) + \n  ggtitle(gene) + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n Key points:\n\n\nTransform count data for summary plots\nCreate summary plots and assess for QC\n\nPCA\nClustering by sample distance\nHeatmaps of gene counts\nIndividual gene counts"
  },
  {
    "objectID": "lesson2_DESeq2.html#extract-deseq2-results",
    "href": "lesson2_DESeq2.html#extract-deseq2-results",
    "title": "Differential Expression with DESeq2",
    "section": "6. Extract DESeq2 results",
    "text": "6. Extract DESeq2 results\nIf we are happy with our QC assessment we can retrieve results from the DESeq object and visualise fold changes between specific comparisons.\nDESeq2 has a results() function which by default will print the results of the last variable in your formula, comparing the last level of this variable with your base-level. In our case this is the conditions MOV10_OE vs Control.\n\nresults(dds)\n\nlog2 fold change (MLE): condition MOV10 OE vs Control \nWald test p-value: condition MOV10 OE vs Control \nDataFrame with 58396 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE       stat      pvalue\n                <numeric>      <numeric> <numeric>  <numeric>   <numeric>\nENSG00000000003 3493.3769     -0.4426597 0.0851357 -5.1994602 1.99868e-07\nENSG00000000005   26.2026     -0.0163884 0.4447545 -0.0368482 9.70606e-01\nENSG00000000419 1600.4515      0.3753645 0.0998817  3.7580902 1.71215e-04\nENSG00000000457  504.6620      0.2532487 0.1053669  2.4034929 1.62393e-02\nENSG00000000460 1112.7132     -0.2626755 0.0852641 -3.0807284 2.06495e-03\n...                   ...            ...       ...        ...         ...\nENSG00000289714  0.000000             NA        NA         NA          NA\nENSG00000289715  0.000000             NA        NA         NA          NA\nENSG00000289716 28.600952       0.112480  0.553978   0.203041    0.839103\nENSG00000289718  0.167725      -1.026277  4.080456  -0.251510    0.801420\nENSG00000289719 14.921394       0.614092  0.547343   1.121950    0.261884\n                       padj\n                  <numeric>\nENSG00000000003 4.12199e-06\nENSG00000000005 9.84458e-01\nENSG00000000419 1.39950e-03\nENSG00000000457 5.80996e-02\nENSG00000000460 1.12268e-02\n...                     ...\nENSG00000289714          NA\nENSG00000289715          NA\nENSG00000289716    0.912842\nENSG00000289718          NA\nENSG00000289719    0.444436\n\n\nHowever, the dds object stores several results. You can see these with the function resultsNames().\n\nresultsNames(dds)\n\n[1] \"Intercept\"                     \"condition_MOV10_KD_vs_Control\"\n[3] \"condition_MOV10_OE_vs_Control\"\n\n\nThe Intercept result is a statistical model that compares gene expression to 0 so is not relevant here. We can see that we have results for both of our MOV10 perturbation experiments vs the control.\nWe can extract a specific result by providing arguments to the results() function. Let’s look at the first comparison in our list, MOV10_OE vs Control.\n\nres<-results(dds,contrast = contrasts[[1]])\nres\n\nlog2 fold change (MLE): condition MOV10_OE vs Control \nWald test p-value: condition MOV10 OE vs Control \nDataFrame with 58396 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE       stat      pvalue\n                <numeric>      <numeric> <numeric>  <numeric>   <numeric>\nENSG00000000003 3493.3769     -0.4426597 0.0851357 -5.1994602 1.99868e-07\nENSG00000000005   26.2026     -0.0163884 0.4447545 -0.0368482 9.70606e-01\nENSG00000000419 1600.4515      0.3753645 0.0998817  3.7580902 1.71215e-04\nENSG00000000457  504.6620      0.2532487 0.1053669  2.4034929 1.62393e-02\nENSG00000000460 1112.7132     -0.2626755 0.0852641 -3.0807284 2.06495e-03\n...                   ...            ...       ...        ...         ...\nENSG00000289714  0.000000             NA        NA         NA          NA\nENSG00000289715  0.000000             NA        NA         NA          NA\nENSG00000289716 28.600952       0.112480  0.553978   0.203041    0.839103\nENSG00000289718  0.167725      -1.026277  4.080456  -0.251510    0.801420\nENSG00000289719 14.921394       0.614092  0.547343   1.121950    0.261884\n                       padj\n                  <numeric>\nENSG00000000003 4.12199e-06\nENSG00000000005 9.84570e-01\nENSG00000000419 1.39950e-03\nENSG00000000457 5.80996e-02\nENSG00000000460 1.12268e-02\n...                     ...\nENSG00000289714          NA\nENSG00000289715          NA\nENSG00000289716    0.912953\nENSG00000289718          NA\nENSG00000289719    0.444436\n\n\nThe results table includes several columns:\n\nbaseMean = Mean number of counts from all samples\nlog2FoldChange = Log2 of the fold change in normalised counts between sample groups in the contrast\nlfcSE = Standard error of the log2 fold change\nstat = The test statistic (Wald test in this case)\npvalue = The pvalue / significance level\npadj = The pvalue adjusted for multiple testing\n\n\nMultiple testing correction and independent filtering\nThe two most important columns in our results table are log2FoldChange, which is the effect size and tells us how much a gene’s expression has changed, and padj which gives us the level of statistical significance. DESeq2 reports adjusted p-values (padj) which are corrected for multiple testing. We should use these values, not the pvalue column, to filter or call significant genes.\nDESeq2 uses the Benjamini-Hochberg method to adjust p-values and control the false discovery rate. So, if you were to filter for genes with a padj<=0.05 you would expect 5% of these to be false positives.\nIf you inspect the result table you may notice that some genes have padj and/or pvalue set to NA. This is because the results() function performs filtering of genes to reduce the total number of genes tested and increase the likelihood of finding significant genes after the multiple testing correction. The more genes we test, the larger the multiple testing correction, so it makes sense to remove genes where we are unlikely to see a statistical effect:\n\nGenes with zero counts in all samples\nGenes with extreme outliers\nGenes with extremely low normalised counts\n\nLet’s look at a summary of our results. We will also set an alpha to tell DESeq which significance threshold to use when summarising results:\n\nsummary(res,alpha=padj_thresh)\n\n\nout of 34774 with nonzero total read count\nadjusted p-value < 0.05\nLFC > 0 (up)       : 2077, 6%\nLFC < 0 (down)     : 2708, 7.8%\noutliers [1]       : 14, 0.04%\nlow counts [2]     : 16900, 49%\n(mean count < 9)\n[1] see 'cooksCutoff' argument of ?results\n[2] see 'independentFiltering' argument of ?results\n\n\nThis is great, we definitely have significant differentially expressed genes!\n\n\nLog Fold Change Shrinkage\nLet’s take a look at these results visually. DESeq2 provides a plotMA() function to create MA plots(log2FoldChange vs the mean of normalised counts), a common way to visualise DE genes.\n\nplotMA(res)\n\n\n\n\nSignificant genes (<=0.05 padj) appear in blue, while non-significant genes are grey. We can immediately see that genes with low counts have much larger variation in log-fold changes. DESeq2 provides the LFCshrink() to shrink the fold change estimates and reduce the “noise” from these genes. We can use it instead of the results() function and these shrunken fold changes are much better for visualising and ranking our data.\n\nlibrary(apeglm)\nresLFC<-lfcShrink(dds,coef = coefficients[1],type=\"apeglm\")\n\nusing 'apeglm' for LFC shrinkage. If used in published research, please cite:\n    Zhu, A., Ibrahim, J.G., Love, M.I. (2018) Heavy-tailed prior distributions for\n    sequence count data: removing the noise and preserving large differences.\n    Bioinformatics. https://doi.org/10.1093/bioinformatics/bty895\n\nsummary(resLFC,alpha=padj_thresh)\n\n\nout of 34774 with nonzero total read count\nadjusted p-value < 0.05\nLFC > 0 (up)       : 2077, 6%\nLFC < 0 (down)     : 2708, 7.8%\noutliers [1]       : 14, 0.04%\nlow counts [2]     : 16900, 49%\n(mean count < 9)\n[1] see 'cooksCutoff' argument of ?results\n[2] see 'independentFiltering' argument of ?results\n\n\nWe can see that the number of significant genes is unaffected. Let’s create a new MA plot.\n\nplotMA(resLFC)\n\n\n\n\nYou should see how the shrunken fold changes will be more useful for downstream analysis of the data.\n\n\nCreate result tables for each of our comparisons\nBefore moving on, we are going to create result tables for each of the comparisons we are interested in. We will also order these by padj so the most significant genes are on top.\n\n## Map each of our coefficients to the lfcShrink function\nresult_list<-coefficients %>% map(~lfcShrink(dds,coef = .x,type = \"apeglm\"))\n\nusing 'apeglm' for LFC shrinkage. If used in published research, please cite:\n    Zhu, A., Ibrahim, J.G., Love, M.I. (2018) Heavy-tailed prior distributions for\n    sequence count data: removing the noise and preserving large differences.\n    Bioinformatics. https://doi.org/10.1093/bioinformatics/bty895\nusing 'apeglm' for LFC shrinkage. If used in published research, please cite:\n    Zhu, A., Ibrahim, J.G., Love, M.I. (2018) Heavy-tailed prior distributions for\n    sequence count data: removing the noise and preserving large differences.\n    Bioinformatics. https://doi.org/10.1093/bioinformatics/bty895\n\nnames(result_list) = coefficients\nresult_list\n\n$condition_MOV10_OE_vs_Control\nlog2 fold change (MAP): condition MOV10 OE vs Control \nWald test p-value: condition MOV10 OE vs Control \nDataFrame with 58396 rows and 5 columns\n                 baseMean log2FoldChange     lfcSE      pvalue        padj\n                <numeric>      <numeric> <numeric>   <numeric>   <numeric>\nENSG00000000003 3493.3769    -0.42009662 0.0858830 1.99868e-07 4.12199e-06\nENSG00000000005   26.2026    -0.00291646 0.1952387 9.70606e-01 9.84458e-01\nENSG00000000419 1600.4515     0.34321370 0.1004344 1.71215e-04 1.39950e-03\nENSG00000000457  504.6620     0.21909429 0.1028038 1.62393e-02 5.80996e-02\nENSG00000000460 1112.7132    -0.23950281 0.0842909 2.06495e-03 1.12268e-02\n...                   ...            ...       ...         ...         ...\nENSG00000289714  0.000000             NA        NA          NA          NA\nENSG00000289715  0.000000             NA        NA          NA          NA\nENSG00000289716 28.600952     0.01510826  0.202870    0.839103    0.912842\nENSG00000289718  0.167725    -0.00643906  0.217131    0.801420          NA\nENSG00000289719 14.921394     0.08953887  0.224710    0.261884    0.444436\n\n$condition_MOV10_KD_vs_Control\nlog2 fold change (MAP): condition MOV10 KD vs Control \nWald test p-value: condition MOV10 KD vs Control \nDataFrame with 58396 rows and 5 columns\n                 baseMean log2FoldChange     lfcSE      pvalue       padj\n                <numeric>      <numeric> <numeric>   <numeric>  <numeric>\nENSG00000000003 3493.3769    -0.00471138 0.0834052 0.948000695 0.98020857\nENSG00000000005   26.2026    -0.07604609 0.1896524 0.198963380 0.42514606\nENSG00000000419 1600.4515     0.14366889 0.1035714 0.095040977 0.26647514\nENSG00000000457  504.6620     0.37636817 0.1174052 0.000214838 0.00284425\nENSG00000000460 1112.7132     0.16791324 0.0894084 0.031705242 0.12650603\n...                   ...            ...       ...         ...        ...\nENSG00000289714  0.000000             NA        NA          NA         NA\nENSG00000289715  0.000000             NA        NA          NA         NA\nENSG00000289716 28.600952     0.05340824  0.181720    0.285774   0.528048\nENSG00000289718  0.167725    -0.00322889  0.178059    0.769643         NA\nENSG00000289719 14.921394    -0.01081164  0.171725    0.816282         NA\n\n\n\n\nFormatting and annotating results\nWe will apply a bit of formatting to our results table and also add some annotations.\n\nConvert to a format where we can use tidyverse verbs\nMove the rownames to a geneID column\nAdd a threshold column for genes we wish to label as significant\nOrder each table by padj so significant genes are at the top\n\n\nresult_list2<-result_list %>% \n  map(~as.data.frame(.x) %>% \n        rownames_to_column(\"geneID\") %>% \n        mutate(threshold=case_when(padj<=padj_thresh & abs(log2FoldChange)>=l2fc_thresh~\"Significant\",T~\"Not Significant\")) %>% \n        arrange(padj) %>% \n        as_tibble()\n  )\nresult_list2\n\n$condition_MOV10_OE_vs_Control\n# A tibble: 58,396 × 7\n   geneID          baseMean log2FoldChange  lfcSE    pvalue      padj threshold \n   <chr>              <dbl>          <dbl>  <dbl>     <dbl>     <dbl> <chr>     \n 1 ENSG00000155363   94561.          7.47  0.134  0         0         Significa…\n 2 ENSG00000189060    7874.          1.52  0.0704 1.33e-104 1.19e-100 Significa…\n 3 ENSG00000173110     257.          6.52  0.357  1.53e- 74 9.12e- 71 Significa…\n 4 ENSG00000270882    2234.          1.73  0.101  1.39e- 66 6.22e- 63 Significa…\n 5 ENSG00000187837    1605.          1.48  0.0936 1.52e- 57 5.30e- 54 Significa…\n 6 ENSG00000265972    5203.          1.38  0.0876 1.78e- 57 5.30e- 54 Significa…\n 7 ENSG00000155090    1699.          1.20  0.0810 8.51e- 51 2.17e- 47 Significa…\n 8 ENSG00000102317    8191.         -0.752 0.0543 1.30e- 44 2.84e- 41 Significa…\n 9 ENSG00000112972   12428.          0.926 0.0670 1.43e- 44 2.84e- 41 Significa…\n10 ENSG00000142002    2395.         -0.765 0.0599 1.86e- 38 3.32e- 35 Significa…\n# ℹ 58,386 more rows\n\n$condition_MOV10_KD_vs_Control\n# A tibble: 58,396 × 7\n   geneID          baseMean log2FoldChange  lfcSE   pvalue     padj threshold  \n   <chr>              <dbl>          <dbl>  <dbl>    <dbl>    <dbl> <chr>      \n 1 ENSG00000116962    6310.          1.10  0.0693 3.89e-58 6.44e-54 Significant\n 2 ENSG00000143183    1784.          1.19  0.0792 3.08e-52 2.55e-48 Significant\n 3 ENSG00000270882    2234.          1.67  0.112  2.47e-51 1.37e-47 Significant\n 4 ENSG00000038274    2424.         -1.07  0.0765 1.37e-45 5.65e-42 Significant\n 5 ENSG00000168036   11651.          0.812 0.0583 4.68e-45 1.55e-41 Significant\n 6 ENSG00000124762    2759.          1.16  0.0834 6.39e-45 1.76e-41 Significant\n 7 ENSG00000116473    2151.         -1.02  0.0735 8.83e-45 2.09e-41 Significant\n 8 ENSG00000082458    4642.         -0.732 0.0563 8.88e-40 1.84e-36 Significant\n 9 ENSG00000109971   22609.          0.739 0.0590 4.83e-37 8.88e-34 Significant\n10 ENSG00000129250    2738.         -1.06  0.0854 7.63e-37 1.24e-33 Significant\n# ℹ 58,386 more rows\n\n\nOur result table contains Ensembl gene identifier but we may want to add more annotations like the gene name and biotype. We can fetch Ensembl annotations from the R package AnnotationHub or from the BioMart website. We already have a file called genes.tsv which has some of this additional information.\n\ngenes<-read_tsv(\"salmon/genes.tsv\")\ngenes\n\n# A tibble: 69,340 × 4\n   gene_id         gene_name   gene_biotype                        entrezid\n   <chr>           <chr>       <chr>                                  <dbl>\n 1 ENSG00000223972 DDX11L1     transcribed_unprocessed_pseudogene     84771\n 2 ENSG00000227232 WASH7P      unprocessed_pseudogene                    NA\n 3 ENSG00000278267 MIR6859-1   miRNA                              102466751\n 4 ENSG00000243485 MIR1302-2HG lncRNA                                    NA\n 5 ENSG00000284332 MIR1302-2   miRNA                              100302278\n 6 ENSG00000237613 FAM138A     lncRNA                                645520\n 7 ENSG00000268020 OR4G4P      unprocessed_pseudogene                    NA\n 8 ENSG00000240361 OR4G11P     transcribed_unprocessed_pseudogene        NA\n 9 ENSG00000186092 OR4F5       protein_coding                         79501\n10 ENSG00000238009 <NA>        lncRNA                                    NA\n# ℹ 69,330 more rows\n\n\nNow we can merge our result tables with the annotations to add extra columns:\n\n## Map all result lists to a function that joins with the anno data\nresult_list_anno<-result_list2 %>% \n  map(~left_join(x=.x,y=genes,by=c(\"geneID\"=\"gene_id\")) %>% \n        mutate(gene_biotype=as.factor(gene_biotype))) ## biotype as a factor\n\nWe will now save these results tables to text files so we can use them outside of R if required. We can create a folder for each of our results.\n\n## Map each of our result names to a function that saves each table in our results_list\nnames(result_list_anno) %>% map(function(x){\n  dir.create(x)\n  write_tsv(result_list_anno[[x]],paste0(x,\"/DEseq_result.tsv\"),col_names = T)\n})\n\n\n\n Key points:\n\n\nExtract results for individual contrasts\nCreate MA plots\nShrink log2 fold change estimates\nAdd annotations to result tables"
  },
  {
    "objectID": "lesson2_DESeq2.html#visualise-deseq2-results",
    "href": "lesson2_DESeq2.html#visualise-deseq2-results",
    "title": "Differential Expression with DESeq2",
    "section": "7. Visualise DESeq2 results",
    "text": "7. Visualise DESeq2 results\nWe have already seen the MA plot but there are many other methods for plotting DESeq2 results. We cover some popular visualisations below.\n\nVolcano plots\nLet’s try a volcano plot, another popular visualisation for DE analysis. Here we are plotting the log fold change on the x-axis against the negative log of our p-values, so that significant genes appear at the top of the plot. We can then see the spread of fold changes in each direction in our set of significant genes.\n\nggplot(result_list_anno[[1]],aes(log2FoldChange,-log10(padj),colour=threshold)) + \n  geom_point() + \n  theme_bw() + \n  ggtitle(coefficients[1])  +\n  theme(legend.key = element_blank())\n\n\n\n\nWe can even use ggrepel to label some of our genes. Let’s select five genes with the lowest adjusted pvalues.\n\nlibrary(ggrepel)\n\nWarning: package 'ggrepel' was built under R version 4.2.3\n\ntopFive<-result_list_anno[[1]] %>% head(n=5)\nggplot(result_list_anno[[1]],aes(log2FoldChange,-log10(padj),colour=threshold)) + \n  geom_point() + \n  geom_text_repel(data=topFive,aes(label = gene_name))+\n  theme_bw() + \n  ggtitle(coefficients[1])  +\n  guides(colour=F)\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nWarning: Removed 40536 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nPlots of DE genes by biotype\nIf we are interested in more than just protein coding genes, we could take a look at the types of RNAs which are represented in our list of DE genes.\nFirst, let’s filter our results for genes which pass our threshold for differential expression.\n\n## Get a list of significant DEGs\nsig_genes<-result_list_anno[[1]] %>% dplyr::filter(threshold==\"Significant\")\n\n## Plot barplot of gene_biotype\nggplot(sig_genes,aes(\"Significant genes\",fill=gene_biotype)) +\n  geom_bar() + \n  theme_bw() + \n  xlab(\"\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\nHeatmaps of genes with largest changes\nNow that we have our results, we can use the log normalised counts we created earlier to plot heatmaps of genes with the largest changes.\n\n## Out of all significant genes, get the 20 with the largest fold change in either direction in MOV10_OE relative to the control\n## Out of all significant genes, get the 50 with the largest fold change in either direction in MOV10_OE relative to the control\ntop20<-result_list_anno[[1]] %>% \n  dplyr::filter(threshold==\"Significant\") %>% \n  arrange(desc(abs(log2FoldChange))) %>% \n  head(n=20) %>% \n  pull(geneID)\n\n## Create a matrix of rld counts and plot the heatmap\nmat<-assay(rld)[top20,]\ncolors <- colorRampPalette( rev(brewer.pal(9, \"RdBu\")) )(255)\npheatmap(mat,color=colors,scale = \"row\",cluster_rows = T,cluster_cols = T,annotation_col = anno)\n\n\n\n\n\n\n Key points:\n\n\nThere are many ways to summarise and visualise DE results\nGet creative!\n\n\n\n\n\n Challenge:\n\nSee if you can produce similar visual outputs and summaries of results for the MOV10_KD_vs_Control comparison."
  },
  {
    "objectID": "lesson1_command_line.html",
    "href": "lesson1_command_line.html",
    "title": "Command Line Analysis",
    "section": "",
    "text": "Set up a project folder\nPerform quality control on RNA-sequencing reads\nAlign reads to a reference genome and perform post alignment filtering\nView read coverage profiles and alignments in a genome browser\nQuantify transcript expression"
  },
  {
    "objectID": "lesson1_command_line.html#getting-started",
    "href": "lesson1_command_line.html#getting-started",
    "title": "Command Line Analysis",
    "section": "1. Getting Started",
    "text": "1. Getting Started\nWe are using the Linux command line to run most of the tools we use today.\n\nLogging in\nWe will use the WACCBIP bioinformatics server for this practical.\nYou will need to use a Terminal app on Mac, Linux or Windows to log in:\nssh USERNAME@aabn.ug.edu.gh\nOnce you have typed in your password, you should see some text and a prompt that looks something like this:\n[USERNAME]@aabn:~$\n\n\nRStudio\nWe will use RStudio in the second part of this workshop to analyse read count data. RStudio can also be used to view the files we create on the server in a genome browser. Check that you can login at http://aabn.ug.edu.gh/auth-sign-in\n\n\nIntegrative Genomics Viewer\nPlease install IGV on your own machine, alternatively you can use the web application.\n\n\n Key points:\n\n\nMake sure you can log in to the bioinformatics server\nMake sure you can log in to RStudio\nCheck that IGV is installed on your machine"
  },
  {
    "objectID": "lesson1_command_line.html#rna-seq-sequencing-data",
    "href": "lesson1_command_line.html#rna-seq-sequencing-data",
    "title": "Command Line Analysis",
    "section": "2. RNA-seq sequencing data",
    "text": "2. RNA-seq sequencing data\nThe data we will we use in this workshop is part of a larger study described in Kenny PJ et al., Cell Rep 2014. The authors investigated interactions between various genes involved in Fragile X syndrome, a disease of aberrant protein production, which results in cognitive impairment and autistic-like features. They sought to show that RNA helicase MOV10 regulates the translation of RNAs involved in Fragile X syndrome.\nThe RNA was extracted from HEK293F cells that were transfected with a MOV10 transgene (MOV10 over-expression), MOV10 siRNA (MOV10 knockdown), or an irrelevant siRNA (Control). For now, we will just look at the over-expression and control samples.\n\n\n Further Learning\n\nIf you are new to RNA-seq, this overview provides an explanation of how RNA-seq libraries are prepared and sequenced for short-read data.\n\nTranscription and RNAs\nIllumina library preparation\nIllumina sequencing\n\nIf you are thinking about performing your own RNA-seq experiments then take a look at these experimental design considerations:\n\nHow many replicates do I need?\nHow many reads do I need?\nWhat type of reads should I use?:\n\nPaired or single end?\nWhat length?\nStranded or unstranded?\n\nConfounding factors\nBatch effects\n\n\n\nRaw Data\nThe raw RNA-seq data is available publicly via GEO and the SRA (sequence read archive).\n\n\nMetadata\nIt is also important to collect metadata (information about the data) that describes the samples and the experimental preparation. Some key things to note about these datasets:\n\nHEK293F is a human cell line so we will align our reads to a human reference.\nThe libraries are stranded so we expect reads to align to genes in a strand specific manner.\nThe libraries were created with the Illumina Tru-seq adapters.\n100bp single-end reads were generated.\nThey contain ~40 million reads per sample. For the purpose of this workshop we have randomly sub-sampled 200000 reads to speed up computation.\nFor each group we have three replicates as described below.\n\n\n\n\nDataset\nDescription\n\n\n\n\nControl_1\nControl, replicate 1\n\n\nControl_2\nControl, replicate 2\n\n\nControl_3\nControl, replicate 3\n\n\nMOV10_OE_1\nMOV10 over-expression, replicate 1\n\n\nMOV10_OE_2\nMOV10 over-expression, replicate 2\n\n\nMOV10_OE_3\nMOV10 over-expression, replicate 3\n\n\n\n\n\nObtaining data\nFirst, make a new directory for this tutorial and move into that directory.\ncd \nmkdir RNA-seq_workshop\ncd RNA-seq_workshop\nNext, create a subfolder called fastq for all of our sequence files and link the raw datasets to this folder:\nmkdir fastq\nln -s /data/swebb/training/RNA-seq_analysis/lesson_1/fastq/*fq.gz fastq/\nAs well as the raw data we will also need access to annotations and reference sequences for the human genome/transcriptome. These are provided for this workshop and should also be linked to your folder:\nln -s /data/swebb/training/RNA-seq_analysis/annotation .\n\n\nFastQ files\nSequencing data will typically be provided to you in fastq format (.fq or .fastq) or as a compressed gzipped fastq (.fq.gz) in order to save space. We can view a gzipped file with the zless command, let’s take a look:\nzless fastq/Control_1.fq.gz | head -n 12\nFastq files contain 4 lines per sequenced read:\n\nLine 1 begins with an ‘@’ character and is followed by a sequence identifier and an optional description\nLine 2 is the raw sequence\nLine 3 begins with a ‘+’ character and is optionally followed by the same sequence identifier\nLine 4 encodes the Phred quality score for the sequence in Line 2 as ASCII characters\n\n\n\n Key points:\n\n\nCreate a project directory\nLink the raw data files to a fastq folder\nCreate a symlink to the annotation data\nUnderstand the fastq file format"
  },
  {
    "objectID": "lesson1_command_line.html#quality-control",
    "href": "lesson1_command_line.html#quality-control",
    "title": "Command Line Analysis",
    "section": "3. Quality control",
    "text": "3. Quality control\nNext we want to assess the quality of our sequencing data and check for any biases and contamination.\n\nFastQ screen\nIt is useful to know if your sequencing library contains the types of sequences you expect. FastQ Screen is a program which searches for contaminants by mapping a sample of your reads to different genomes. It allows you to specify a custom set of genomes, e.g. all of the organisms you work on, along with PhiX, vectors and other contaminants commonly seen in sequencing experiments. We will not run this in the workshop but an example is given below.\n\n# Example, do not run\nfastq_screen fastq/*fq.gz --outdir fastq \n# * is a wild card character so includes all files that end fq.gz\n\nThe output shows that most of the reads align to the human genome and that no reads align uniquely to other organisms:\n\n\n\nFastQC\nFastQC provides simple quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses to quickly assess your data before proceeding with analysis.\nfastqc fastq/*.fq.gz\nFastQC will create report files for each of your datasets which we can view in the browser. We will go through each of the images during the workshop. For future reference, specific guidance on how to interpret the output of each module is provided in the fastqc help pages.\nAn example of poor quality sequencing at the end of short reads:\n\nThe software gives a pass, fail or warning flag for each test based on what we would expect from a regular DNA-sequencing run. It is important to realise that FastQC does not understand the origin of your data and that different datasets will have different characteristics. For instance RNA sequencing often involves the use of random hexamer primers that are not as random as you might expect. The profile below in the first ~15 bases is perfectly normal for these samples but will be flagged as an error by FastQC:\n\nVisit the QCFail website for more examples and advice on quality control for NGS datasets.\n\n\nMultiQC\nWe can view summaries of multiple reports at once by using multiqc:\nmultiqc -o fastq fastq\nMultiQC searches for report files in a directory and compiles them into a single report. Open the multiqc_report.html file in the fastq directory via a web browser to see how the raw datasets compare. Here we have the output FastQC. MultiQC works with the outputs of many other tools, including Fastq_Screen. We will see more of these later.\nIf we look at the adapter content and over represented sequences sections we can see a small amount of contamination particularly at the ends of the sequencing reads.\n\n\n Key points:\n\n\nGenerate QC reports with fastQC and multiqc\nLearn to assess and perform quality control of raw reads"
  },
  {
    "objectID": "lesson1_command_line.html#quality-trimming-and-adapter-removal",
    "href": "lesson1_command_line.html#quality-trimming-and-adapter-removal",
    "title": "Command Line Analysis",
    "section": "4. Quality trimming and adapter removal",
    "text": "4. Quality trimming and adapter removal\nFrom the FastQC report we can see that the overall quality of our sequencing is good, however it is good practice to perform some pre-processing and filtering of reads. Poor quality sequencing can make a read less alignable, so it is good practice to quality trim the ends of reads until we get to the high quality portion. Trimming is not always necessary as some mapping programs will trim the reads for you or perform soft clipping where only part of a read is required to align, but studies have shown that pre-processing generally improves alignment rate if done correctly.\nSequencing libraries are normally constructed by ligating adapters to fragments of DNA or RNA. If your read length is longer than your fragment then sequenced reads will contain the adapter sequence. Adapter removal is a necessary consideration for your QC workflow, especially if adapters are detected by FastQC.\nAn example of adapter contamination at the end of reads: \nOnce reads have been trimmed they will vary in length. You may want to filter out reads that are now too short to be uniquely mapped. Normally a cutoff of 20-30bp is standard.\n\nTrim Galore!\nIn this workshop we will use Trim Galore! for adapter and quality trimming. It is a wrapper around the popular tool Cutadapt which finds and removes unwanted sequences from high-throughput sequencing reads.\nCutadapt can perform quality trimming, adapter removal and read filtering as well as many other operations to prepare your reads for optimal alignment. We will run trim galore! with the following parameters:\n\nq : Trim reads from the 3’ end with the given quality threshold (Phred score)\nlength : Filter out reads below this length\nfastqc : Run fastqc on the trimmed reads\nillumina : Trim the standard Illumina adapter sequences\ncores : Use multiple CPU cores to speed up the computation\no : the name of the output folder\n\nFrom here onwards, we are just going to look at one control and one MOV10OE sample, to save time\n## Create a new folder for trimmed data\nmkdir trim_galore \n\ntrim_galore --fastqc -q 20 --illumina --length 20 --cores 4 -o trim_galore fastq/Control_1.fq.gz\n\ntrim_galore --fastqc -q 20 --illumina --length 20 --cores 4 -o trim_galore fastq/MOV10_OE_1.fq.gz\nTo view a trim_galore report:\nless trim_galore/Control_1.fq.gz_trimming_report.txt\n\n\n Discussion\n\n\nWhat percentage of reads contain an adapter sequence?\nHow many reads were discarded for being too short?\n\n\n\nLet’s compare the fastqc reports. Run multiqc on the trimmed data and compare this with the reports for the raw data.\nmultiqc -f -o trim_galore trim_galore\n\n\nOther trimming software worth investigating\nTrim Galore simplifies the Cutadapt command and also runs fastqc on the trimmed data. However, it is worth looking through the full functionality of Cutadapt which has many options for filtering and trimming reads. Trimmomatic is another tool which has a very sensitive algorithm for detecting adapters, especially in paired-end reads.\n\nCutadapt\nTrimmomatic\n\n\n\nFurther QC steps\nIt may be worth looking into a few other tools for quality control of RNA-seq data.\n\nSortMeRNA can remove sequences that map to ribosomal RNAs. Ideally, your library preparation should include steps to deplete ribosomal RNAs but you can also use tools to remove these from your analysis.\nRSeQC is a QC tool specifically for RNA-seq.\n\n\n\n Key points:\n\n\nCheck for contaminants\nAssess sequence quality\nUnderstand scripting\nTrim and filter your sequencing reads"
  },
  {
    "objectID": "lesson1_command_line.html#read-alignment",
    "href": "lesson1_command_line.html#read-alignment",
    "title": "Command Line Analysis",
    "section": "5. Read Alignment",
    "text": "5. Read Alignment\nThere are many tools available for mapping reads to genomes and transcriptomes, each with their own purposes and strengths. RNA-seq data requires a splice-aware aligner that can handle splice junctions in the sequencing reads. The two most popular aligners are STAR, which is very fast, and HISAT2, which is very accurate.\n\n\nGenome assemblies and indexing\nFirst, we need to select a reference genome to align to. Every time a reference genome is released or updated it is given a new name, often referred to as the genome build or assembly (..hg18, hg19, hg38). It is important to realise that different builds of the same genome are different sequences and thus their co-ordinate systems are incomparable. For instance position 10000000 on chr1 is T in hg19 and G in hg38.\nWe are going to map our reads to a recent release of the human genome (hg38 or GRCh38). We need to create an index file from the GRCh38 fasta sequence so that STAR can quickly access the reference sequences. Many of these indexes are pre-computed on our servers and stored under the /homes/genomes directory for everyone to use. The indexes for this workshop have are available in the annotation we linked earlier.\nThe code below shows how these were generated with STAR. You do not need to run this again, it will take a long time to run!!!\n\n## Download sequence files and latest annotations from Ensembl\n#wget http://ftp.ensembl.org/pub/release-106/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz  ## Use primary assembly without Alt contigs but including scaffolds\n#wget http://ftp.ensembl.org/pub/release-106/gtf/homo_sapiens/Homo_sapiens.GRCh38.106.gtf.gz\n\n#gzip -d Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n#gzip -d Homo_sapiens.GRCh38.106.gtf.gz\n\n## Build STAR index\n#STAR --runMode genomeGenerate --genomeDir STAR_index_hg38.ensembl106 --genomeFastaFiles Homo_sapiens.GRCh38.dna.primary_assembly.fa --sjdbGTFfile Homo_sapiens.GRCh38.106.gtf --sjdbOverhang 100 --runThreadN 20\n\n\n\nMapping reads with STAR\nNow that we have an index, we can align our reads to the human genome with STAR. Because STAR uses a large amount of memory, we are only going to map reads to chr1 for this workshop, however we will look at the complete mapping as a group.\nmkdir STAR ## make a new folder for read alignments\n\nSTAR --genomeDir /data/swebb/training/RNA-seq_analysis/annotation_small/STAR_index_hg38_chr1.ensembl106 --readFilesCommand zcat --readFilesIn trim_galore/Control_1_trimmed.fq.gz --runThreadN 2 --outSAMtype BAM SortedByCoordinate --outFileNamePrefix STAR/Control_1. --outWigType wiggle --outWigNorm RPM --genomeLoad LoadAndRemove --limitBAMsortRAM 30000000000\n\nSTAR --genomeDir /data/swebb/training/RNA-seq_analysis/annotation_small/STAR_index_hg38_chr1.ensembl106 --readFilesCommand zcat --readFilesIn trim_galore/MOV10_OE_1_trimmed.fq.gz --runThreadN 2 --outSAMtype BAM SortedByCoordinate --outFileNamePrefix STAR/MOV10_OE_1.  --outWigType wiggle --outWigNorm RPM --genomeLoad LoadAndRemove --limitBAMsortRAM 30000000000\nWe are using the following parameters:\n\ngenomeDir : The location of the STAR genome index\nreadFilesInCommand : The unix command for reading a *.gz file\nreadFilesIn : The location of the fq.gz file\nrunThreadN : The number of CPU threads available to each STAR process\noutSAMtype : The output file format\noutFileNamePrefix : Used to name the outputs\nsjdbGTFfile : A gene model and splice junction annotation file in gtf format\noutWigType : Additional output of read coverage profiles\noutWigNorm : Normalisation strategy for read coverage profiles\ngenomeLoadLoadAndRemove : The reference genome index is very large (30Gb) and uses a lot of memory. This option allows users to share the same index in memory.\n--limitBAMsortRAM : Set the RAM limit for sorting BAM files\n\nNote that we do not need to include the –sjdbGTFfile here as it was already used in creating the index. We can provide the annotations at either step or provide a different file with additional annotation.\nWe recommend reading the STAR manual to fully understand all of the parameters and output options. Running alignment software with default parameters may not be the best option for your data.\nWhen your alignment has completed, take a look at the output STAR report:\nless STAR/Control_1.Log.final.out\n\n\n Discussion\n\n\nHow many input reads did we have?\nHow many of these align to a single location on the genome?\nHow many reads map to multiple locations?\n\n\n\n\nSAM/BAM/CRAM format and Samtools\nThe standard output for most mapping software is SAM (sequence alignment/map format). SAM files contain many columns that describe the position of each alignment as well as information on the quality of the alignment, mismatches, the number of times a read mapped, mapping of paired ends and other custom flags and statistics.\nSAM files can be very large so there are compressed alternatives BAM and CRAM. The samtools package has many useful tools for viewing, filtering and manipulating files in SAM format. We will use some of these below.\nTake a look at the SAM format specification and the first few lines of your BAM output using samtools.\nsamtools view STAR/Control_1.Aligned.sortedByCoord.out.bam | less\nThe second column is the SAM flag and contains coded information about each alignment.\n\n\n Discussion\n\nUse the Explain SAM flags resource to find out more about the alignments in your file. They appear to contain the flags 0,16,256 and 272.\n\n\nWe can also see the sam file header using the -H flag which contains information on the parameters and indexes used to create the file.\nsamtools view -H STAR/Control_1.Aligned.sortedByCoord.out.bam | less\nWe can index our bam files with samtools index. This creates an index file for quick programmatic access to the binary file. Indexing is required for some of the samtools programs to work as well as for viewing the reads on genome browsers.\n## Index the bam files\nsamtools index STAR/Control_1.Aligned.sortedByCoord.out.bam\nsamtools index STAR/MOV10_OE_1.Aligned.sortedByCoord.out.bam\nThe command samtools idxstats outputs the number of reads aligned to each sequence in our reference.\nsamtools idxstats STAR/Control_1.Aligned.sortedByCoord.out.bam\n\n\n Discussion\n\nThe third column represents the number of alignments.\n\nWhy are there so few alignments to the Y chromosome?\nWhy are there any alignments to the Y chromosome?\n\n\n\n\n\n Key points:\n\n\nAlign reads to a reference genome with STAR\nUnderstand the SAM file format\nRNA-seq data must use a splice-aware aligner"
  },
  {
    "objectID": "lesson1_command_line.html#post-alignment-processing",
    "href": "lesson1_command_line.html#post-alignment-processing",
    "title": "Command Line Analysis",
    "section": "6. Post alignment processing",
    "text": "6. Post alignment processing\nNow that we have aligned our reads we may want to do some filtering before any downstream analysis. Make sure you are aware of the alignments that are reported by your mapping program and the parameters used. For instance, are unmapped reads included in the BAM file? Are all alignments to repeats reported or just one? Are paired-end alignments still reported if only one end maps?\n\nFiltering reads with samtools\nThere are many ways to filter your BAM files with samtools and other programs to remove unwanted alignments that may negatively affect your downstream analysis. First lets look at the alignments contained in one of our bam files with samtools flagstat:\nsamtools flagstat STAR/Control_1.Aligned.sortedByCoord.out.bam\nFlagstat seems to report more alignments than the number of reads shown in our STAR report, how can this be? Our BAM file contains one record per alignment and some reads may align to multiple locations. STAR assigns each read a primary alignment, which is selected randomly from the top scoring alignments.\nWe can use samtools view -f to include, and -F to exclude reads with a given SAM flag. The flag 260 is the sum of 4 (read is unmapped) and 256 (not primary alignment). This will filter unmapped reads and non-primary alignments to give us a single alignment for each mapped read.\n## Filter out secondary alignments and index bam files\n\nsamtools view -F 260 -bh -o  STAR/Control_1.primary.bam STAR/Control_1.Aligned.sortedByCoord.out.bam\nsamtools index STAR/Control_1.primary.bam\n\nsamtools view -F 260 -bh -o  STAR/MOV10_OE_1.primary.bam STAR/MOV10_OE_1.Aligned.sortedByCoord.out.bam\nsamtools index STAR/MOV10_OE_1.primary.bam\nThe -bh option tells samtools view to output in BAM format and to include the header.\nIf we run samtools flagstat on this filtered bam file we should now have one alignment per mapped read.\nsamtools flagstat STAR/Control_1.primary.bam\n\n\n\nMultimap reads and Duplicate reads\nMultimap and duplicate reads are often confused so it is important to understand what these are and how they affect your data:\n\nMultimap reads = The read exists once in your library and aligns to multiple repeat locations in the reference genome.\nDuplicate reads = Multiple unique reads with the same sequence that align to identical locations in the genome.\n\n\nMultimap reads are difficult to analyse as their ambiguity can confound results. Many applications require the use of unique alignments only, thus multimap reads often need to be removed from your BAM file.\nAlignment tools assign a mapping quality to each read (column 5 in BAM) between 0 and 255 that describes the confidence in the alignment position.\nYou should be aware that mapping qualities differ between mapping tools. STAR uses mapping quality scores of 0 and 255 to represent multimap and unique reads respectively. Filtering out reads with a mapping quality < 255 means that all remaining reads align to a single unique position. We can use samtools view -q to filter based on mapping quality.\n## Filter for unique reads and index\n\nsamtools view -b -q 255 STAR/Control_1.primary.bam -o STAR/Control_1.unique.bam\nsamtools index STAR/Control_1.unique.bam\n\nsamtools view -b -q 255 STAR/MOV10_OE_1.primary.bam -o STAR/MOV10_OE_1.unique.bam\nsamtools index STAR/MOV10_OE_1.unique.bam\nDuplicate reads are often observed as tall spikes in your read depth profile where reads are stacked directly on top of each other. A high level of duplication in your library may be due to over amplification by PCR or contamination. In RNA-seq experiments the chances of selecting identical sequences are much higher as our sample size is much smaller (length of transcriptome vs length of genome) and multiple copies of the same sequence (transcripts) exist independently. Thus, it is common practice to retain duplicate reads.\n\n\n Further Learning\n\nLearn more about duplication and removing duplicate reads:\n\nDuplication bias\nThe Picard package has many useful utilities for manipulating SAM/BAM files. The MarkDuplicates tool will check the alignment positions for duplicate reads and mark or remove them from your data depending on how you wish to treat them.\n\n\n\n\n\nRemoving alignments to regions of the genome\nIn some cases you may wish to remove reads that align to specific regions of the genome. For instance, if you still have a lot of ribosomal RNAs that will skew your downstream analysis.\n\nbedtools intersect can remove reads from BAM files that align to specific genomic locations.\n\n\n\n Key points:\n\n\nUse samtools to summarise and filter your alignments\nConsider filtering your BAM files\n\nPrimary alignments\nUnique alignments\nDuplicate reads\nRegions of the genome"
  },
  {
    "objectID": "lesson1_command_line.html#visualising-alignments-on-a-genome-browser",
    "href": "lesson1_command_line.html#visualising-alignments-on-a-genome-browser",
    "title": "Command Line Analysis",
    "section": "7. Visualising alignments on a genome browser",
    "text": "7. Visualising alignments on a genome browser\nIt is always a good idea to visually inspect your data on a genome browser. Has the sequencing worked as expected? Are there noticeable differences between samples by eye? Do RNA-seq reads align to the expected strand?\n\nConverting BAM files to bigWig\nBAM files contain information about each read, which is great if you want to look at individual alignments and splice junctions, but they are typically large and slow to work with. If we are only interested in read coverage we can convert our BAM files to graphs of sequencing depth per base.\nThe wiggle file contains genomic intervals, represented by chromosome and position co-ordinates, along with a score. In this case the score represents read coverage, how many reads overlap with that position. A compressed version of this format, called bigWig, is used by genome browsers.\nYou may have noticed that we already asked STAR to output wiggle files. STAR gives us wiggle files for both unique and unique+multimap reads and also splits these up by strand. Let’s take a look at one of these files:\nhead STAR/Control_1.Signal.Unique.str1.out.wig\nLet’s convert the unique files to bigWig format for visualisation. The tool wigToBigWig requires three arguments, an input file, a file of chromosome lengths, and the name of the output file.\nmkdir visualisation ## Create a folder for visualisation files\n\n## Make bigWig files for forward strand - Control\nwigToBigWig STAR/Control_1.Signal.Unique.str1.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/Control_1.unique.r.bw\n\n## Make bigWig files for reverse strand - Control\nwigToBigWig STAR/Control_1.Signal.Unique.str2.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/Control_1.unique.f.bw\n\n## Make bigWig files for forward strand - MOV10_OE\nwigToBigWig STAR/MOV10_OE_1.Signal.Unique.str1.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/MOV10_OE_1.unique.r.bw\n\n## Make bigWig files for reverse strand - MOV10_OE\nwigToBigWig STAR/MOV10_OE_1.Signal.Unique.str2.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/MOV10_OE_1.unique.f.bw\n\n\n\nRNA-seq normalisation\nNormalisation is the process of correcting read coverage levels in order to compare expression levels between genes and different samples. Normalisation methods need to account for several factors in RNA-seq data:\n\nSequencing depth - Total number of sequenced reads differs between samples\nGene length - Longer genes will have more reads than shorter genes expressed at the same level\nRNA composition - The presence of a few highly differentially expressed genes can skew normalisation between samples. This is especially important in differential expression analysis.\n\nSeveral RNA-seq normalisation strategies exist:\n\nRPM - Reads per million mapped reads (sequence depth correction)\nRPKM/FPKM - Reads/fragments per kilobase per million mapped reads (sequence depth and gene length correction)\nTPM - Transcripts per million (sequence depth and gene length correction)\n\nYou may have noticed that we used RPM normalisation to create our wiggle files earlier. This is the only option in STAR and is fine for visual QC of your data.\nOf the options above, TPM normalisation is most suitable for comparing expression levels between genes and between samples. If you plan to perform comparitive analysis on aligned data, we recommend using deepTools bamCoverage, which can generate TPM normalised bigWig files from BAM files. The bamCoverage tool also has several options for filtering, smoothing and normalising read coverage profiles.\nSome analysis pipelines use genomeCoverageBed but be aware this does not output normalised values unless scaling factors are supplied explicitly.\nNone of these normalisation strategies are appropriate for differential expression analysis with gene count data. You will see later on that differential expression packages employ their own normalisation methods to handle sequencing depth and RNA composition.\n\n\n Further Learning\n\nMore on RNA-seq normalisation:\n\nAn overview of normalisation methods\nTPM vs RPKM\n\n\n\n\n\nVisualising data on IGV\nIGV (Integrative genomics viewer) is a powerful genome browser from the Broad institute. It is perfect for viewing your sequencing files as loading data is easy, common formats are understood, views are customisable and navigation is quick.\nLet’s also add our bam files to the visualisation folder.\ncd visualisation\nln -s ../STAR/*unique.bam* .\ncd ../\nIt is best to download the desktop app for use on your own machine but if you can also access the web app at https://igv.org/app/.\nOpen IGV and set the genome to hg38, then find your visualisation folder in RStudio. You will need to download the files you require and open them locally in IGV.\nLoad the two bigWig tracks for MOV10_OE_1 into IGV:\n\nFirst, let’s navigate the chromosome:\n\nUse the + / - zoom bar at the top right\nDrag and highlight an area to zoom on the genome ruler\nType a position or gene identifier in to the search box\n\nNow let’s customise our view:\n\nSelect Tracks->Fit Data To Window To automatically set track heights to fill the view (not available on web app).\nRight click on the Refseq genes track (or use the cog on web app) and switch between display modes Collapsed, Expanded and Squished. (Use the horizontal panel divider to adjust height)\nUse the right click menu or cog on the bigwig track name to customise the display. Try the following:\nRename the track\nChange the track colour\nChange the graph type\nChange the windowing function\nAdjust the data range\nSet the scale to Autoscale. This automatically sets the Y-axis to the height of the tallest peak in your view.\nSelect multiple tracks and set the scale to Group autoscale. This will automatically scale tracks together.\n\n\n\n Discussion\n\nThere are two large spikes on chr1 (forward strand) and chr6 (reverse strand).\n\nWhat are these genes?\nWould you expect to see similar spikes in the control?\nLoad a control bigWig and check.\nWere we correct in assuming our data was reverse stranded?\n\n\n\n\nNow load a corresponding BAM file MOV10_OE_1.unique.bam for one of your tracks. Make sure the .bai index file is in the same folder as the BAM. Navigate to the MOV10 gene, you should be able to see all of the aligned reads.\n\nUse the menu for the BAM file to customise the way reads are displayed.\n\n\n Discussion\n\n\nCan you identify mismatches in read alignments?\nCan you identify reads mapping across splice junctions?\nCan you create a sashimi plot?\n\n\n\n\n\n\n\nOther genome browsers\nWe recommend IGV as it allows you to quickly explore your data. Several other genome browsers exist and the Ensembl and UCSC websites are particularly useful for viewing your data online alongside published experimental data and genomic annotations that exist in their databases.\n\n\n Key points:\n\n\nConvert BAM files to bigWig for read coverage visualisation\nConsider how to normalise read coverage profiles\nView your files in a genome browser such as IGV"
  },
  {
    "objectID": "lesson1_command_line.html#quantifying-expression-levels",
    "href": "lesson1_command_line.html#quantifying-expression-levels",
    "title": "Command Line Analysis",
    "section": "8. Quantifying expression levels",
    "text": "8. Quantifying expression levels\nOnce we have inspected our data and are happy with our alignments, we can quantify expression levels for annotated transcripts. Pseudo-alignment tools, such as Salmon, map sequencing reads directly to transcripts. They are extremely fast, can handle multi-map reads, and take into account multiple isoforms, transcript lengths and sequencing biases when estimating abundance.\n\nCreate a Salmon index\nLike STAR, Salmon requires an index for alignment. The indexes require fasta sequences of all coding and non-coding RNAs as well as the genomic sequence. The Salmon index for this workshop has been pre-computed using the code below. You do not need to run this as it will already be in the annotation folder you linked previously.\n\n## Download cdna and ncrna fasta files from Ensembl\n#wget http://ftp.ensembl.org/pub/release-106/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz\n#wget http://ftp.ensembl.org/pub/release-106/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz\n\n## Create Salmon indexes\n\n## Concatenate hg38 cdna and ncrna\n#zcat Homo_sapiens.GRCh38.cdna.all.fa.gz Homo_sapiens.GRCh38.ncrna.fa.gz > Homo_sapiens.GRCh38.cdna.ncrna.fa.tmp\n\n## Make sure header is transcript name only and remove transcript version number\n#perl -lane 'if(m/^>/){$id=(split \" \",$_)[0];$id=(split \"\\\\.\",$id)[0];print $id;}else{print $_;}' Homo_sapiens.GRCh38.cdna.ncrna.fa.tmp  > Homo_sapiens.GRCh38.cdna.ncrna.fa\n#rm Homo_sapiens.GRCh38.cdna.ncrna.fa.tmp\n\n## Get genome chr sequences in decoys.txt\n#grep \"^>\" Homo_sapiens.GRCh38.dna.primary_assembly.fa | sed s/\">\"//g | cut -f 1 -d \" \" > decoys.txt\n\n## Cat transcriptome and genome to make gentrome file: \n#cat Homo_sapiens.GRCh38.cdna.ncrna.fa Homo_sapiens.GRCh38.dna.primary_assembly.fa > Homo_sapiens.GRCh38.cdna.ncrna.gentrome.fa\n#gzip Homo_sapiens.GRCh38.cdna.ncrna.gentrome.fa\n\n## Build Salmon index\n#salmon index -t Homo_sapiens.GRCh38.cdna.ncrna.gentrome.fa.gz -d decoys.txt -p 24 -i hg38.cdna.ncrna.salmon.index -k 31\n\n\n\n Further Learning\n\nCreating Salmon indexes is more complicated than STAR but the bioinformatics team may be able to help you out or there may be pre-computed indexes available. You can also read more about the method here.\n\n\n\nPseudo-alignment with Salmon\nWe can now run Salmon to estimate expression levels of transcripts. Biases in sequencing data can lead to over/under estimation of expression of certain transcripts and Salmon has some functionality to overcome this. We will use the salmon quant command with the following arguments:\n\ni : location of the index files\nr : location of the fq.gz file (use -1,-2 for paired end files)\nl : library type\nseqBias : correct sequencing bias in the data\ngcBias : correct GC bias in the data\no : name of the output folder\n\n\nmkdir salmon ## Make a folder for salmon output\n\n## Quantify expression with salmon\nsalmon quant -i annotation/hg38.cdna.ncrna.salmon.index -l SR -r trim_galore/Control_1_trimmed.fq.gz -p 1 --seqBias --gcBias -o salmon/Control_1\n\nsalmon quant -i annotation/hg38.cdna.ncrna.salmon.index -l SR -r trim_galore/MOV10_OE_1_trimmed.fq.gz -p 1 --seqBias --gcBias -o salmon/MOV10_OE_1\n\nThe library type describes the type of reads used in the experiment. Here we have single (S), reverse-stranded (R) reads. Check the documentation for other arguments.\nThe main output of Salmon is a quant.sf file, take a look at one of these files:\n\nless salmon/Control_1/quant.sf\n\nFor each transcript we have five columns:\n\nThe transcript identifier\nThe transcript length (in bp)\nThe effective length (described in detail below)\nTPM (transcripts per million), which is computed using the effective length\nThe estimated read count (‘pseudocount’)\n\n\n\n Discussion\n\nWhat exactly is the effective length?\nThe sequence composition of a transcript affects how many reads are sampled from it. While two transcripts might have identical length, depending on the sequence composition we are more likely to generate fragments from one versus the other. The transcript that has a higer likelihood of being sampled, will end up with the larger effective length. The effective length is thus a corrected transcript length to account for sequence-specific and GC biases.\n\n\n\n\n Key points:\n\n\nUse pseudo-aligner tools like Salmon to estimate transcript abundance\nUnderstand the Salmon output files\n\n\n\n\n\nFinal reports\nThe last thing we want to do is to run MultiQC on our folder to compile the reports from Trim_galore, STAR and Salmon:\nmultiqc -f .\n\n\n\n Discussion\n\nTake a look at the multiqc report in your public folder:\n\nWhy are there two different values for % Aligned in the general statistics?\nAre you happy with the % of aligned reads?\nWhy does the MOV10 sample have more duplicate reads?\n\n\n\n\nTidy Up!\nFiles are large and disk space is expensive, remove any unwanted or temporary files from your folder. We should always keep the raw data (fastq) and our final processed datasets (BAM, bigWig, quant.sf etc) as well as the code we used to generate them. Where you can, convert files to compressed or binary formats to save space e.g. fq to fq.gz, SAM to BAM, wig to bigWig\nrm trim_galore/*trim*fq.gz #Remove trimmed fastq temporary files\nrm STAR/*.wig #Remove wig files once converted to bigWig"
  },
  {
    "objectID": "lesson1_command_line.html#shell-scripts-pipelining-and-parallelisation",
    "href": "lesson1_command_line.html#shell-scripts-pipelining-and-parallelisation",
    "title": "Command Line Analysis",
    "section": "9. Shell scripts, pipelining and parallelisation",
    "text": "9. Shell scripts, pipelining and parallelisation\nUp until now we have run command line tools on each one of our datasets in serial, this means they run one after the other. In this tutorial we only have a few small datasets and the tools run relatively quickly, but this approach won’t scale well to multiple large datasets.\nWe also have to manually input each command and wait for each job to finish, which can be time consuming.\nA more efficient approach is to create a script that will run all of our datasets in parallel.\n\nBash script\nBelow is an example of a bash script which runs all of the steps of our analysis.\n\n## PREPARATION\n\n## Create folders\nmkdir fastq\nmkdir trim_galore\nmkdir STAR \nmkdir salmon\nmkdir visualisation\n\n## Link the annotation folder\nln -s /data/swebb/training/RNA-seq_analysis/annotation .\n\n## Link the raw data to the fastq folder\nln -s /data/swebb/training/RNA-seq_analysis/lesson_1/fastq/$1.fq.gz fastq/\n\n## QC\n\n## FastQC\nfastqc fastq/$1.fq.gz\n\n## PREPROCESSING \ntrim_galore --fastqc -q 20 --illumina --length 20 --cores 4 -o trim_galore fastq/$1.fq.gz\n\n## run STAR\nSTAR --genomeDir /data/swebb/training/RNA-seq_analysis/annotation_small/STAR_index_hg38_chr1.ensembl106 --readFilesCommand zcat --readFilesIn trim_galore/$1_trimmed.fq.gz --runThreadN 2 --outSAMtype BAM SortedByCoordinate --outFileNamePrefix STAR/$1. --sjdbGTFfile annotation/Homo_sapiens.GRCh38.106.gtf --outWigType wiggle --outWigNorm RPM --genomeLoadLoadAndRemove --limitBAMsortRAM 30000000000\n\n## index STAR\nsamtools index STAR/$1.Aligned.sortedByCoord.out.bam\n\n## filter for primary reads\nsamtools view -F 260 -bh -o  STAR/$1.primary.bam STAR/$1.Aligned.sortedByCoord.out.bam\nsamtools index STAR/$1.primary.bam\n\n## filter for unique reads\nsamtools view -b -q 255 STAR/$1.primary.bam -o STAR/$1.unique.bam; samtools index STAR/$1.unique.bam\n\n## Convert wig to bigWig for both strands\nwigToBigWig STAR/$1.Signal.Unique.str1.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/$1.unique.r.bw\nwigToBigWig STAR/$1.Signal.Unique.str2.out.wig annotation/Homo_sapiens.GRCh38.dna.primary_assembly.len visualisation/$1.unique.f.bw\n\n## link bigWigs to visualisation folder\ncd visualisation\nln -s ../STAR/$1*unique.bam* .\ncd ../\n\n## run Salmon\nsalmon quant -i annotation/hg38.cdna.ncrna.salmon.index -l SR -r trim_galore/$1_trimmed.fq.gz -p 5 --seqBias --gcBias -o salmon/$1\n\n## Tidy up\n\nrm trim_galore/$1*trim*fq.gz #Remove trimmed fastq temporary files\nrm STAR/$1*.wig #Remove wig files once converted to bigWig\n\n##Multi QC on everything\nmultiqc -f .\n\nYou will notice that the sample names have been replaced with $1. This is a bash programming device that recognises the first argument supplied to a script.\nLet’s make a new folder and copy this script into it:\n\ncd\nmkdir RNA-seq_workshop_auto\ncd RNA-seq_workshop_auto\ncp /data/swebb/training/RNA-seq_analysis/lesson_1/RNA-seq_pipeline.sh .\n\nWe can now run this script with one of our samples by supplying the sample name as an argument:\n\nsh RNA-seq_pipeline.sh Control_1\n\nWhen the script completes you can use the tree command to see all of your outputs.\nWe could then run the pipeline again using MOV10_OE_1, but it would also be nice if we could run both samples at the same time. Thankfully, Unix has a command called parallel which allows us to do this.\n\n\nparallel\nparallel allows you to run tools on multiple datasets at the same time. The following example lists all of your gzipped fastq files and pipes “|” them into parallel.\n\n## EXAMPLE DO NOT URN\nls fastq/*fq.gz | parallel -j 6 fastqc {} &\n\n\nls lists files ending with .fq.gz in your fastq directory and pipes the names into the parallel command.\nThe parallel -j flag stands for jobs and tells parallel to run 6 processes at the same time.\nIn this case we are running fastqc and the {} is a place holder for the filenames we are piping in.\nThe & character runs these jobs in the background so we can continue to use the terminal.\n\nWe can also use parallel to run our script. First, copy the samples.txt file which contains the names of the samples we want to run:\n## Copy the samples file\ncp /data/swebb/training/RNA-seq_analysis/lesson_1/samples.txt .\n## Print the samples file\ncat samples.txt\nNow let’s pipe the names of our samples into parallel:\n\ncat samples.txt | parallel -j 2 sh RNA-seq_pipeline.sh {}\n\nThis will take a while to run, but once complete you can use the tree command again to see the output files.\nWe now have our alignments (BAM), visualisation files (bigWig) and transcript quantification (quant.sf) and this is normally a branching point for downstream analyses.\n\n\n Key points:\n\n\nSave your analysis as a script and run it in one go\nLearn to manage your data"
  }
]